# SolutionChallenge
Main parts of our code :

Part 1 : importing libraries 

nltk : The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing.

tensorflow : open-source library developed by Google primarily for deep learning applications. It also supports traditional machine learning.

tflearn : TFlearn is a modular and transparent deep learning library built on top of Tensorflow.

pickle : used in serializing and deserializing a Python object structure.

random : generate random numbers

numpy :  open-source numerical Python library. NumPy contains a multi-dimensional array and matrix data structures.

json : JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax.


Part 2 : importing and shaping data to fit the model.

Part 3 : Creating the neural network model.

Part 4 : Feeding the model.

Part 5 : defining the function to find the correlation between a specific post title, and every other post description to spot the trending posts, and generate the government surveys.
